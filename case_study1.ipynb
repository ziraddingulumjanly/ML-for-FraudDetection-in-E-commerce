{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CASE STUDY 1\n",
    "CONTRIBUTOR: MURAD ISMAYILZADA UMCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe kernel failed to start as 'get_ipython' could not be imported from 'most likely due to a circular import'.\n",
      "\u001b[1;31mClick <a href='https://aka.ms/kernelFailuresModuleImportErrFromFile'>here</a> for more info."
     ]
    }
   ],
   "source": [
    "# pip install pandas matplotlib seaborn scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_rows', 600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust = pd.read_csv(\"casestudy1_MuradIsmayilzadaCustomer.csv\") #customer details\n",
    "trans = pd.read_csv(\"casestudy1_MuradIsmayilzadaTransaction.csv\") #transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust.info(),trans.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'customerEmail' column\n",
    "merged_df = pd.merge(cust, trans, on='customerEmail', how='inner')\n",
    "\n",
    "# Verify the merged dataframe\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the specified columns\n",
    "merged_df = merged_df.drop(columns=['Unnamed: 0_x', 'Unnamed: 0_y'])\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EDA On the Merged _DF\n",
    "1.Basic Information about the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the dataframe\n",
    "print(\"First few rows of the dataframe:\")\n",
    "print(merged_df.head())\n",
    "\n",
    "# Get basic information about the dataframe\n",
    "print(\"\\nSummary of the dataframe:\")\n",
    "print(merged_df.info())\n",
    "\n",
    "# Summary statistics of numerical columns\n",
    "print(\"\\nSummary statistics of numerical columns:\")\n",
    "print(merged_df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values in the dataframe:\")\n",
    "print(merged_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Data Distribution and Visualization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "numerical_features = ['No_Transactions', 'No_Orders', 'No_Payments']\n",
    "# Histograms for numerical features\n",
    "plt.figure(figsize=(10, 6))\n",
    "merged_df[numerical_features].hist(bins=20)\n",
    "plt.suptitle('Histograms of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for numerical features\n",
    "sns.boxplot(data=merged_df[numerical_features])\n",
    "plt.title('Boxplots of Numerical Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As there are Outliers in the No_Payments and No_Orders columns, Removing is the best solution for proper further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = merged_df[numerical_features].quantile(0.25)\n",
    "Q3 = merged_df[numerical_features].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = (merged_df[numerical_features] < lower_bound) | (merged_df[numerical_features] > upper_bound)\n",
    "\n",
    "# Remove outliers\n",
    "merged_df_cleaned = merged_df[~outliers.any(axis=1)]\n",
    "merged_df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the outliers constitute only about 3.3% of the total data (27 out of 819 rows), and without a clear understanding of their origin or impact, I lean towards removing them. Removing outliers in this scenario seems reasonable as it's a relatively small portion of the dataset and their presence may potentially distort the analysis or model performance. However, it's important to document this decision and consider the potential implications of removing outliers on the overall analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the first quartile (Q1) and third quartile (Q3)\n",
    "Q1 = merged_df[numerical_features].quantile(0.25)\n",
    "Q3 = merged_df[numerical_features].quantile(0.75)\n",
    "\n",
    "# Calculate the interquartile range (IQR)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Identify outliers\n",
    "outliers = (merged_df[numerical_features] < lower_bound) | (merged_df[numerical_features] > upper_bound)\n",
    "\n",
    "# Get rows containing outliers\n",
    "outlier_rows = merged_df[outliers.any(axis=1)]\n",
    "\n",
    "\n",
    "outlier_rows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_categorical_features = ['paymentMethodRegistrationFailure', 'paymentMethodType', 'paymentMethodProvider', 'transactionFailed', 'orderState']\n",
    "\n",
    "# Store the numerical counts for each category in a dictionary\n",
    "numerical_counts = {}\n",
    "for feature in additional_categorical_features:\n",
    "    counts = merged_df_cleaned[feature].value_counts()\n",
    "    numerical_counts[feature] = counts\n",
    "\n",
    "# Display numerical counts\n",
    "for feature, counts in numerical_counts.items():\n",
    "    print(f'Numerical counts for {feature}:')\n",
    "    print(counts)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_categorical_features = ['paymentMethodRegistrationFailure', 'paymentMethodType', 'paymentMethodProvider', 'transactionFailed', 'orderState']\n",
    "\n",
    "for feature in additional_categorical_features:\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    ax = sns.countplot(data=merged_df_cleaned, x=feature)\n",
    "\n",
    "    # Calculate percentages for each category\n",
    "    total_count = len(merged_df_cleaned)\n",
    "    for p in ax.patches:\n",
    "        percentage = '{:.1f}%'.format(100 * p.get_height() / total_count)\n",
    "        x = p.get_x() + p.get_width() / 2\n",
    "        y = p.get_height()\n",
    "        ax.annotate(percentage, (x, y), ha='center', va='bottom')\n",
    "\n",
    "    plt.title(f'Count Plot of {feature}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "somthing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_cleaned\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = merged_df_cleaned[[\"No_Transactions\",\"No_Orders\",\"No_Payments\",\n",
    "                                        \"paymentMethodRegistrationFailure\",\n",
    "                                        \"Fraud\",\"transactionAmount\",\"transactionFailed\"]].corr()\n",
    "\n",
    "# Heatmap of correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transaction Metrics and Fraud Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot for No_Transactions\n",
    "sns.countplot(data=merged_df_cleaned, x='No_Transactions', hue='Fraud', ax=axes[0])\n",
    "axes[0].set_title('No_Transactions vs Fraud')\n",
    "axes[0].set_xlabel('No_Transactions')\n",
    "axes[0].set_ylabel('Count')\n",
    "\n",
    "# Plot for No_Orders\n",
    "sns.countplot(data=merged_df_cleaned, x='No_Orders', hue='Fraud', ax=axes[1])\n",
    "axes[1].set_title('No_Orders vs Fraud')\n",
    "axes[1].set_xlabel('No_Orders')\n",
    "axes[1].set_ylabel('Count')\n",
    "\n",
    "# Plot for No_Payments\n",
    "sns.countplot(data=merged_df_cleaned, x='No_Payments', hue='Fraud', ax=axes[2])\n",
    "axes[2].set_title('No_Payments vs Fraud')\n",
    "axes[2].set_xlabel('No_Payments')\n",
    "axes[2].set_ylabel('Count')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_cleaned['Transaction_Success_Rate'] = merged_df_cleaned['No_Transactions'] / (merged_df_cleaned['No_Transactions'] + merged_df_cleaned['transactionFailed'])\n",
    "\n",
    "#Reasoning: This feature captures the proportion of successful transactions for each customer,\n",
    "#providing insights into their transaction success rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Order Frequency\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merged_df_cleaned['Order_Frequency'] = merged_df_cleaned['No_Orders'] / merged_df_cleaned['No_Transactions']\n",
    "#Reasoning: Order frequency gives an idea of how often a customer places orders relative to the number of transactions \n",
    "# they make. \n",
    "# It could indicate whether a customer tends to make multiple orders per transaction or vice versa.\n",
    "merged_df_cleaned = merged_df_cleaned.copy()\n",
    "merged_df_cleaned['Order_Frequency'] = merged_df_cleaned['No_Orders'] / merged_df_cleaned['No_Transactions']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Historical behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_cleaned['Past_Fraud_Transactions'] = merged_df_cleaned['Fraud'].cumsum().shift(fill_value=0)\n",
    "#Reasoning:It provides insight into a customer's historical involvement in fraudulent activities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0\n",
    "data = merged_df_cleaned.fillna(0)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.select_dtypes(include=['object']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cat_cols contains the names of categorical columns\n",
    "cat_cols = ['customerEmail',\n",
    " 'customerPhone',\n",
    " 'customerDevice',\n",
    " 'customerIPAddress',\n",
    " 'customerBillingAddress',\n",
    " 'transactionId',\n",
    " 'orderId',\n",
    " 'paymentMethodId',\n",
    " 'paymentMethodType',\n",
    " 'paymentMethodProvider',\n",
    " 'orderState'] \n",
    "\n",
    "# Create a copy of the DataFrame to avoid modifying the original data\n",
    "data_encoded = data.copy()\n",
    "\n",
    "# Iterate over each categorical column\n",
    "for col in cat_cols:\n",
    "    # Calculate the frequency of each category\n",
    "    freq = data_encoded[col].value_counts(normalize=True)\n",
    "    \n",
    "    # Map the frequency values to the original categories\n",
    "    data_encoded[col + '_freq_encoded'] = data_encoded[col].map(freq)\n",
    "\n",
    "# Drop the original categorical columns if needed\n",
    "data_encoded.drop(cat_cols, axis=1, inplace=True)\n",
    "data_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE   Transaction_TotalAmount HAS BEEN DELETED bE CAREFUL\n",
    "# Importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "df_selected = data_encoded[['No_Transactions', 'No_Orders', 'No_Payments', 'Fraud',\n",
    "       'paymentMethodRegistrationFailure', 'transactionAmount',\n",
    "       'transactionFailed', 'Transaction_Success_Rate', 'Order_Frequency',\n",
    "       'Past_Fraud_Transactions',\n",
    "       'customerEmail_freq_encoded', 'customerPhone_freq_encoded',\n",
    "       'customerDevice_freq_encoded', 'customerIPAddress_freq_encoded',\n",
    "       'customerBillingAddress_freq_encoded', 'transactionId_freq_encoded',\n",
    "       'orderId_freq_encoded', 'paymentMethodId_freq_encoded',\n",
    "       'paymentMethodType_freq_encoded', 'paymentMethodProvider_freq_encoded',\n",
    "       'orderState_freq_encoded']]\n",
    "\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = df_selected.drop('Fraud', axis=1)\n",
    "y = df_selected['Fraud']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build a Random Forest Classifier model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Feature Importances\n",
    "feature_importances = model.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame to store feature names and their importance scores\n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "\n",
    "# Sort the DataFrame by importance in descending order\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance DataFrame\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "X = data_encoded.drop(columns=['Fraud'])\n",
    "y = data_encoded['Fraud']\n",
    "\n",
    "# Initialize a random forest classifier \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Initialize RFE with the classifier and the number of features to select\n",
    "rfe = RFE(estimator=clf, n_features_to_select=10)\n",
    "\n",
    "# Fit RFE to the data\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = pd.DataFrame({'Feature': X.columns, 'Selected': rfe.support_})\n",
    "\n",
    "# Print the selected features\n",
    "print(selected_features[selected_features['Selected']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model  Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Select the features\n",
    "selected_features = [\n",
    "    'No_Orders', 'No_Payments', 'transactionAmount', 'Past_Fraud_Transactions',\n",
    "     'customerEmail_freq_encoded', 'customerDevice_freq_encoded',\n",
    "    'customerIPAddress_freq_encoded', 'customerBillingAddress_freq_encoded',\n",
    "    'paymentMethodId_freq_encoded'\n",
    "]\n",
    "\n",
    "# Prepare the feature matrix X and target vector y\n",
    "X = data_encoded[selected_features]\n",
    "y = data_encoded['Fraud']  # Assuming 'Fraud' is the target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation (Accuracy=0.94)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-score: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True Negative (TN): The model correctly predicted 68 instances as negative.\n",
    "False Positive (FP): The model incorrectly predicted 2 instances as positive when they were actually negative.\n",
    "False Negative (FN): The model incorrectly predicted 9 instances as negative when they were actually positive.\n",
    "True Positive (TP): The model correctly predicted 80 nstances as positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Generate classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances from the model\n",
    "feature_importances = rf_classifier.feature_importances_\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(selected_features, feature_importances)\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
